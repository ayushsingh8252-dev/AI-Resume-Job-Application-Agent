{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b20845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584e9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d5811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobAgent(TypedDict, total=False):\n",
    "    \n",
    "    #Initial user input\n",
    "    name: str\n",
    "    job_title: str\n",
    "    experience: int   # 0 = fresher\n",
    "    pdf_path: str\n",
    "    jd: str\n",
    "    email: Optional[str]\n",
    "    linkedin: Optional[str]\n",
    "\n",
    "    #Initial user input\n",
    "    resume_text: str\n",
    "    sections : List[str]\n",
    "    missing_fields: List[str]\n",
    "    score: float\n",
    "    feedback: str\n",
    "    interview_questions: List[str]\n",
    "    recommended_courses: List[str]\n",
    "    job_links: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99760d13",
   "metadata": {},
   "source": [
    "MAKING ALL THE FUNCTION DEFINED TO RE-MAP THE GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecda98d",
   "metadata": {},
   "source": [
    "STEP 1 = EXTRACTION\n",
    "#here we will load the pdf and extract all the \n",
    "#text and store in any list formate\n",
    "#this function will return a string which is here text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd0e4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "def extraction(state : JobAgent) -> JobAgent:\n",
    "    pdf_path = state[\"pdf_path\"]\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    text = \"\"\n",
    "    for doc in docs:\n",
    "        text += doc.page_content + \"\\n\"\n",
    "    \n",
    "    state[\"resume_text\"] = text\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae6ea8",
   "metadata": {},
   "source": [
    "STEP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e9b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(state : JobAgent) -> JobAgent:\n",
    "    text = state.get(\"resume_text\")\n",
    "    headings = [\n",
    "        \"SUMMARY\", \"OBJECTIVE\",\n",
    "        \"SKILLS\", \"TECHNICALSKILLS\",\n",
    "        \"EDUCATION\",\n",
    "        \"EXPERIENCE\", \"WORKEXPERIENCE\",\n",
    "        \"PROJECTS\", \"PROJECT\",\n",
    "        \"CERTIFICATIONS\",\n",
    "        \"ACHIEVEMENTS\",\n",
    "        \"INTERNSHIPS\",\n",
    "        \"LANGUAGES\"\n",
    "    ]\n",
    "    required_words = [\"github\", \"gmail.com\", \"linkedin\", \"leetcode\"]\n",
    "\n",
    "    #cheking required\n",
    "    missing = []\n",
    "    lower_text = text.lower()\n",
    "    \n",
    "    for word in required_words:\n",
    "        if word not in lower_text:\n",
    "            missing.append(word)\n",
    "    \n",
    "    #section splitting\n",
    "    sections = {\"OTHER\" : \"\"}\n",
    "    current = \"OTHER\"\n",
    "\n",
    "    for line in text.split(\"/n\"):\n",
    "        line = line.strip()\n",
    "        if not line :\n",
    "            continue\n",
    "\n",
    "        normalised = re.sub(r\"[^A-Za-z]\", \"\", line).upper()\n",
    "\n",
    "        if normalised in headings:\n",
    "            current = normalised\n",
    "            sections[current] = \"\"\n",
    "        else :\n",
    "            sections[current] += line + \"\\n\"\n",
    "\n",
    "    state[\"missing_fields\"] = missing\n",
    "    state[\"sections\"] = sections\n",
    "    \n",
    "    return state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ffa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_\n",
    "def missing(state : JobAgent) -> JobAgent:\n",
    "    prompt = Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb233f",
   "metadata": {},
   "source": [
    "NODES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6bc25",
   "metadata": {},
   "source": [
    "we can store all this info in cache and if in future \n",
    "the user give jd we will give me perceatge how fit he is or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JobAgent)\n",
    "#NODE\n",
    "\n",
    "graph.add_node('extraction', extraction)\n",
    "graph.add_node('preprocess', preprocess)\n",
    "#major part\n",
    "graph.add_node('missing', missing)\n",
    "graph.add_node('assestment', assesment)\n",
    "#graph.add_node('voice', voice)\n",
    "graph.add_node('interview', interview)\n",
    "#resources\n",
    "graph.add_node('dsa', dsa)\n",
    "graph.add_node('job_sites', job_sites)\n",
    "graph.add_node('courses', courses)\n",
    "\n",
    "#summay and feedback\n",
    "graph.add_node('jd_feedback', jd_feedback)\n",
    "\n",
    "#now if the feedback is good we will mail the recutier and messge in linkdn\n",
    "#update in excell so that he can track "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554d686",
   "metadata": {},
   "source": [
    "EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6588d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDGE\n",
    "graph.add_edge(START, 'extraction')\n",
    "graph.add_edge('extraction', 'preprocess')\n",
    "graph.add_edge('preprocess', 'missing')\n",
    "graph.add_edge('missing', 'assestment')\n",
    "#here we can add a condition edges where if he/she get 70% right he will \n",
    "#not get interview question he will direcly get interviwe and dsa \n",
    "graph.add_edge('assestment', 'interview')\n",
    "graph.add_edge('interview', 'dsa')\n",
    "graph.add_edge('dsa', 'job_sites')\n",
    "graph.add_edge('job_sites', 'courses')\n",
    "graph.add_edge('courses', 'jd_feedback')\n",
    "graph.add_edge(\"jd_feedback\", END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
