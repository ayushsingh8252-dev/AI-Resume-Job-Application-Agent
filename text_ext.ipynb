{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe288b5",
   "metadata": {},
   "source": [
    "DOING ALL THE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d9bd568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb72663",
   "metadata": {},
   "source": [
    "ADDING LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb541b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature = 0,\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82b24b",
   "metadata": {},
   "source": [
    "Loading pdf and extracting text for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ccef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ayush Singh \n",
      "ayushrajput8252@gmail.com | +917209602122 | linkedin.com/in/ayush-singh \n",
      " \n",
      "Summary \n",
      "GenAI / AI-ML Engineer specializing in RAG pipelines, LLM applications, LangChain/LangGraph workflows, and \n",
      "AI Agents. Built production-style RAG systems, OCR-based verification automation, and transfer learning models \n",
      "using Python, vector databases, FastAPI, and Docker. Hackathon winner (Top 10/1000 teams) with strong \n",
      "problem-solving background (1000+ DSA problems solved). \n",
      "Education \n",
      "Parul University, B.Tech in Computer Science 2022 – 2026 \n",
      "Experience \n",
      "Capgemini, Pre-Joining Technical Training Program Jan 2026 – Present \n",
      "• Selected through campus recruitment and received an Offer of Intent (LOI). \n",
      "• Currently undergoing structured pre-joining training in DSA, OOP, debugging, and coding \n",
      "best practices. \n",
      "• Solving company-style coding assignments with focus on edge cases and time complexity. \n",
      "Skills \n",
      "Languages : Java, C++, Python                                                                                  \n",
      "GenAI: RAG, LangChain, LangGraph, Embeddings, Prompt Engineering \n",
      "Machine Learning: Supervised Learning, Feature Engineering, Model \n",
      "Evaluation                                                                                                                           \n",
      "Backend/Deployment : FastAPI, REST APIs, Docker, Streamlit \n",
      "Databases: Vector Databases (FAISS/Chroma), SQL (MySQL)                                                                                                        \n",
      "Deep Learning: CNN, Transfer Learning, PyTorch \n",
      "Projects \n",
      " \n",
      "Local Vendor Automation - AI/ML Developer (Hackathon Top 10/1000, ₹5000 Prize) Github \n",
      "Tech Stack:: Python, LangChain, Gemini API, Ollama, EasyOCR, Transfer Learning, RAG  \n",
      "• Built an AI onboarding automation system with OCR PAN verification and fraud checks.. \n",
      "• Developed transfer learning image classifier for auto product categorization.. \n",
      "• Built a FastAPI backend to connect OCR + classifier + RAG chatbot into one integrated workflow. \n",
      "• Implemented RAG chatbot + safety filtering layer for grounded FAQ responses. \n",
      " \n",
      "AI Blog Writing Agent -  LangGraph Multi-Agent + RAG System (Feb 2026 – Present) Github \n",
      "Tech Stack:  Python, LangGraph, LangChain, RAG, Embeddings, Vector DB, Pydantic, Streamlit  \n",
      "• Built a planning-first multi-agent blog writing system using LangGraph orchestration. \n",
      "• Integrated RAG pipeline (chunking, embeddings, retrieval) for grounded research-based blog generation  \n",
      "• Implemented router-based workflow and structured outputs using Pydantic schemas. \n",
      "• Deployed Streamlit UI for an end-to-end production-style demo (working) \n",
      " ACHIEVEMENTS \n",
      " \n",
      "• PU Code Hackathon 3.0: Top 5 out of 1000 teams, awarded ₹5000 prize \n",
      "• Competitive Programming: GeeksforGeeks 3-Star, CodeChef 2-Star \n",
      "• Rankings Top 0.5% in University in GFG and Codilio \n",
      "• Solved 1000+ DSA problems across LeetCode, GFG, CodeChef, Codeforces \n",
      "• Google Developer Student Clubs (GDSC): Core Member (Competitive Programming Team)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r'C:\\AYUSH\\comet\\Comet_AI_Assistance\\AyushSingh_AIMl_Resume_2026_compressed.pdf'\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "#add in text \n",
    "text = \"\"\n",
    "for doc in docs:\n",
    "    text += doc.page_content + \"\\n\"\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e45ae",
   "metadata": {},
   "source": [
    "TEXT EXTRACTION BASED ON HEADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aadb5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "HEADINGS = [\n",
    "    \"SUMMARY\", \"OBJECTIVE\",\n",
    "    \"SKILLS\", \"TECHNICAL SKILLS\",\n",
    "    \"EDUCATION\",\n",
    "    \"EXPERIENCE\", \"WORK EXPERIENCE\",\n",
    "    \"PROJECTS\", \"PROJECT\",\n",
    "    \"CERTIFICATIONS\",\n",
    "    \"ACHIEVEMENTS\",\n",
    "    \"INTERNSHIPS\",\n",
    "    \"LANGUAGES\"\n",
    "]\n",
    "\n",
    "def split_heading(text):\n",
    "    sections = {\"OTHER\" : \"\"}\n",
    "    current = \"OTHER\"\n",
    "\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "\n",
    "        if not line :\n",
    "            continue\n",
    "\n",
    "        normalized = re.sub(r\"[^A-Za-z]\", \"\", line).upper().strip()\n",
    "\n",
    "        if normalized in HEADINGS:\n",
    "            current = normalized\n",
    "            sections[current] = \"\"\n",
    "        else:\n",
    "            sections[current] += line + \"\\n\"\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0abba56",
   "metadata": {},
   "source": [
    "INITIAL BASIC CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2eb5de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Resume Contains All necessary info\n"
     ]
    }
   ],
   "source": [
    "sections = split_heading(text)\n",
    "\n",
    "count = 0\n",
    "\n",
    "if sections.get(\"SKILLS\") or sections.get(\"TECHNICAL SKILLS\"):\n",
    "    count += 1\n",
    "\n",
    "if sections.get(\"SUMMARY\") or sections.get(\"OBJECTIVE\"):\n",
    "    count += 1\n",
    "\n",
    "if sections.get(\"EXPERIENCE\") or sections.get(\"WORK EXPERIENCE\"):\n",
    "    count += 1\n",
    "\n",
    "if sections.get(\"INTERNSHIPS\"):\n",
    "    count += 1\n",
    "\n",
    "if sections.get(\"PROJECTS\") or sections.get(\"PROJECT\"):\n",
    "    count += 1\n",
    "\n",
    "\n",
    "if count >= 4:\n",
    "    print(\"Your Resume Contains All necessary info\")\n",
    "else:\n",
    "    print(\"Some field missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c4182",
   "metadata": {},
   "source": [
    "SENDING SUMMARY AND SKILLS AND TELLING IF THEY ALLIGNS OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e0a268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Title: genai engineer\n",
      "Skills Title: ai engineer\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 1) title from summary\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"Act like a professional IT recruiter. Read this summary:\\n{summary}\\n\"\n",
    "    \"Give exactly one job title that matches it. \"\n",
    "    \"Output must be lowercase and max 2 words.\"\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | llm | parser\n",
    "result1 = chain1.invoke({\"summary\": sections.get(\"SUMMARY\", \"\")})\n",
    "\n",
    "# 2) title from skills\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"Act like a professional IT recruiter. Read these skills:\\n{skills}\\n\"\n",
    "    \"Give exactly one job title that matches it. \"\n",
    "    \"Output must be lowercase and max 2 words.\"\n",
    ")\n",
    "\n",
    "chain2 = prompt2 | llm | parser\n",
    "result2 = chain2.invoke({\"skills\": sections.get(\"SKILLS\", \"\")})\n",
    "\n",
    "print(\"Summary Title:\", result1)\n",
    "print(\"Skills Title:\", result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab5217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "GOOD\n"
     ]
    }
   ],
   "source": [
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"Compare these two job titles:\\n\"\n",
    "    \"1) {t1}\\n\"\n",
    "    \"2) {t2}\\n\\n\"\n",
    "    \"Return similarity score between 0 and 1 (only number).\"\n",
    ")\n",
    "chain3 = prompt3 | llm | parser\n",
    "score = float(chain3.invoke({\"t1\" : result1, \"t2\": result2}))\n",
    "print(score)\n",
    "if score > 0.8:\n",
    "    print(\"GOOD\")\n",
    "else:\n",
    "    print(\"Change skill and summary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c996526",
   "metadata": {},
   "source": [
    "Now do a web search through duckduck go or travily extract insignt about this\n",
    "1. this job tiltle\n",
    "2. question not genric but from interview experiences \n",
    "3. user get 2 option 1. free to chat 2. live vc which give marks on the basis of voice modulalation, clarity, how good he spoke, sound, relevancy and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850954b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingAPIKeyError",
     "evalue": "No API key provided. Please provide the api_key attribute or set the TAVILY_API_KEY environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingAPIKeyError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtavily\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TavilyClient\n\u001b[32m      2\u001b[39m api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m client = \u001b[43mTavilyClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#here result2 is from skills\u001b[39;00m\n\u001b[32m      5\u001b[39m title = result2\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AYUSH\\comet\\ans\\Lib\\site-packages\\tavily\\tavily.py:19\u001b[39m, in \u001b[36mTavilyClient.__init__\u001b[39m\u001b[34m(self, api_key, proxies, api_base_url, client_source, project_id)\u001b[39m\n\u001b[32m     16\u001b[39m     api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingAPIKeyError()\n\u001b[32m     21\u001b[39m resolved_proxies = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m: proxies.get(\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;28;01melse\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_HTTP_PROXY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m: proxies.get(\u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;28;01melse\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_HTTPS_PROXY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     24\u001b[39m }\n\u001b[32m     26\u001b[39m resolved_proxies = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m resolved_proxies.items() \u001b[38;5;28;01mif\u001b[39;00m v} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mMissingAPIKeyError\u001b[39m: No API key provided. Please provide the api_key attribute or set the TAVILY_API_KEY environment variable."
     ]
    }
   ],
   "source": [
    "from tavily import TavilyClient\n",
    "api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "client = TavilyClient(api_key=api_key)\n",
    "#here result2 is from skills\n",
    "title = result2\n",
    "query = f\"{title} placement roadmap trends for 2026\"\n",
    "\n",
    "response = client.search(\n",
    "    query = query,\n",
    "    search_depth=\"advanced\",\n",
    "    max_results = 4,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True\n",
    ")\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
